#ifndef GRAPH_PUBLIC_INTERFACE_BACKEND_HPP
#define GRAPH_PUBLIC_INTERFACE_BACKEND_HPP

#include <vector>
#include <string>
#include <atomic>

#include "oneapi/dnnl/dnnl_config.h"
#include "oneapi/dnnl/dnnl_common_types.h"
#include "oneapi/dnnl/dnnl_graph_types.h"

namespace dnnl {
namespace impl {
namespace graph {

#define RESERVED_BACKEND_ID 0

// using dnnl_graph_graph = dnnl_graph_graph;
// using dnnl_graph_logical_tensor_t = dnnl_graph_logical_tensor_t;
// using dnnl_status_t = dnnl_status_t;
// using dnnl_engine_kind_t = dnnl_engine_kind_t;
// using dnnl_graph_partition_policy_t = dnnl_graph_partition_policy_t;
// using layout_type = dnnl_graph_layout_type_t;

class backend_t;
class backend_registry_t;

std::vector<const backend_t *> DNNL_API &dnnl_get_registered_backends();

void DNNL_API dnnl_register_backend(const backend_t *abackend);

std::string DNNL_API dnnl_print_backend_name(const backend_t* bkd);

class backend_t {
public:
    backend_t(const std::string &name, float priority)
        : name_(name), priority_(priority), id_(get_counter()) {}

    virtual ~backend_t() = default;

    const std::string &get_name() const { return name_; };
    size_t get_id() const { return id_; }
    float get_priority() const { return priority_; }

    /// Return the physical memory size of the buffer described by the passed
    /// logical tensor
    /// @param lt The logical tensor to get memory size. If it's layout_type
    ///     is opaque, then it's layout id must be generated by this backend.
    ///     This should be guaranteed by frontend
    /// @return The memory size
    virtual size_t get_mem_size(const dnnl_graph_logical_tensor_t &lt) const = 0;

    /// Check whether two logical tensor is similar (similar means two
    /// logical tensors can be converted to same backend md)
    /// @param lhs
    /// @param rhs
    /// @return true or false
    /// @note This is a default implementation. It regards two logical
    ///     tensors as similar if they are equal bit by bit except their
    ///     ids. Each backend can override this method to provide specific
    ///     check.
    virtual bool compare_logical_tensor(
            const dnnl_graph_logical_tensor_t &lhs, const dnnl_graph_logical_tensor_t &rhs) const {
        bool equal = (lhs.ndims == rhs.ndims)
                && (lhs.data_type == rhs.data_type)
                && (lhs.layout_type == rhs.layout_type);

        if (!equal) return false;
        if (lhs.ndims == 0 || lhs.ndims == -1) return true;

        // check dims
        equal = std::equal(std::begin(lhs.dims),
                std::begin(lhs.dims) + lhs.ndims, std::begin(rhs.dims));
        if (!equal) return false;

        // check layout information
        if (lhs.layout_type == dnnl_graph_layout_type_t::dnnl_graph_layout_type_strided) {
            return std::equal(std::begin(lhs.layout.strides),
                    std::begin(lhs.layout.strides) + lhs.ndims,
                    std::begin(rhs.layout.strides));
        } else if (lhs.layout_type == dnnl_graph_layout_type_t::dnnl_graph_layout_type_opaque) {
            return lhs.layout.layout_id == rhs.layout.layout_id;
        } else {
            return true;
        }
    }

    /// Run pass on the given graph and generate backend specific
    /// partition_impl objects, which will be stored on the graph
    /// temporarily
    /// @param agraph The graph to be partitioned
    /// @param policy The partition policy
    /// @return The status code
    virtual dnnl_status_t get_partitions(dnnl_graph_graph &agraph, dnnl_graph_partition_policy_t policy)
            = 0;

    /// Check if a backend supports a specific engine kind
    virtual bool support_engine_kind(dnnl_engine_kind_t kind) const = 0;

private:
    static size_t get_counter() {
        static std::atomic<size_t> counter {RESERVED_BACKEND_ID + 1};
        size_t ret = counter;
        counter++;
        return ret;
    }

    std::string name_;
    float priority_;
    size_t id_;
};

// class pass_registry;

// void DNNL_API dnnl_create_pass_registry(pass_registry* dst);

// void DNNL_API dnnl_register_pass_in_registry(const pass_registry *reg);

// void DNNL_API dnnl_on_graph_run_passes(const pass_registry& reg, dnnl_graph_graph& graph, dnnl_graph_partition_policy_t policy);

}
}
}

#endif
